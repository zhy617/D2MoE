import argparse
import os
import glob
import torch
from tqdm import tqdm

try:
    import safetensors.torch
except ImportError:
    print("Error: `safetensors` library not found. Please run `pip install safetensors`.")
    exit()

def check_tensors_in_state_dict(state_dict, device: str):
    """è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥ä¸€ä¸ªstate_dictä¸­çš„æ‰€æœ‰å¼ é‡æ˜¯å¦æœ‰NaN/Infã€‚"""
    for key, tensor in state_dict.items():
        if not torch.all(torch.isfinite(tensor)):
            nan_count = torch.isnan(tensor).sum().item()
            inf_count = torch.isinf(tensor).sum().item()
            return key, nan_count, inf_count
    return None, 0, 0

def verify_model_shards_incrementally(model_path: str):
    """
    ä»¥åˆ†ç‰‡æ–¹å¼ã€å†…å­˜é«˜æ•ˆåœ°æ‰«ææ¨¡åž‹æ–‡ä»¶ï¼Œå¹¶åœ¨CPUå’ŒGPUä¸Šåˆ†åˆ«æ£€æŸ¥ã€‚
    """
    print("="*60)
    print(f"ðŸ”¬ Starting incremental verification for model at: {model_path}")
    print("="*60)

    if not os.path.isdir(model_path):
        print(f"Error: Directory not found at '{model_path}'")
        return

    checkpoint_files = sorted(glob.glob(os.path.join(model_path, "*.safetensors")))
    if not checkpoint_files:
        print("Error: No .safetensors files found.")
        return

    corrupted_stages = []
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„CUDAè®¾å¤‡
    use_gpu = torch.cuda.is_available()
    if not use_gpu:
        print("Warning: No CUDA device found. Will only perform CPU checks.")

    for filepath in tqdm(checkpoint_files, desc="Scanning Shards"):
        filename = os.path.basename(filepath)

        # --- 1. CPU æ£€æŸ¥ ---
        try:
            state_dict_cpu = safetensors.torch.load_file(filepath, device="cpu")
            corrupted_key, nans, infs = check_tensors_in_state_dict(state_dict_cpu, "cpu")
            if corrupted_key:
                issue = f"File: {filename}, Stage: CPU Loading, Tensor: {corrupted_key}, NaNs: {nans}, Infs: {infs}"
                corrupted_stages.append(issue)
                # tqdm.write(f"âŒ Corruption detected on CPU for {filename}")
                continue # å¦‚æžœCPUåŠ è½½å°±æœ‰é—®é¢˜ï¼Œæ²¡å¿…è¦å†æ£€æŸ¥GPU
        except Exception as e:
            issue = f"File: {filename}, Stage: CPU Loading, Error: {e}"
            corrupted_stages.append(issue)
            # tqdm.write(f"âŒ Error loading {filename} to CPU")
            continue

        # --- 2. GPU æ£€æŸ¥ (å¦‚æžœå¯ç”¨) ---
        if use_gpu:
            try:
                # ä¸ºäº†èŠ‚çœå†…å­˜ï¼Œå…ˆåˆ é™¤CPUä¸Šçš„å‰¯æœ¬
                del state_dict_cpu
                torch.cuda.empty_cache()

                state_dict_gpu = safetensors.torch.load_file(filepath, device="cuda:0")
                corrupted_key, nans, infs = check_tensors_in_state_dict(state_dict_gpu, "cuda:0")
                if corrupted_key:
                    issue = f"File: {filename}, Stage: GPU Loading, Tensor: {corrupted_key}, NaNs: {nans}, Infs: {infs}"
                    corrupted_stages.append(issue)
                    # tqdm.write(f"âŒ Corruption detected on GPU for {filename}")
                
                # æ¸…ç†æ˜¾å­˜
                del state_dict_gpu
                torch.cuda.empty_cache()

            except Exception as e:
                issue = f"File: {filename}, Stage: GPU Loading, Error: {e}"
                corrupted_stages.append(issue)
                # tqdm.write(f"âŒ Error loading {filename} to GPU")

    # --- æœ€ç»ˆæŠ¥å‘Š ---
    print("\n" + "="*60)
    print(" " * 18 + "Final Verification Report")
    print("="*60)
    
    if not corrupted_stages:
        print("âœ… Verdict: The model appears to be CLEAN on both CPU and GPU.")
        print("No corruption was detected during the loading process.")
    else:
        print("âŒ Verdict: CORRUPTION DETECTED during the loading process!")
        print("Issues were found at the following stages:")
        for issue in corrupted_stages:
            print(f"  - {issue}")
        print("\nRecommendation: The problem likely lies in the CUDA driver, PyTorch environment, or hardware during CPU->GPU data transfer.")
    
    print("="*60)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Verify model shards on CPU and GPU.")
    parser.add_argument("--model_path", type=str, required=True, help="Path to the model directory.")
    args = parser.parse_args()
    verify_model_shards_incrementally(args.model_path)